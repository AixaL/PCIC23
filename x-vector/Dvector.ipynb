{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "# import speechbrain as sb\n",
    "# from speechbrain.lobes.models.Xvector import Xvector\n",
    "\n",
    "\n",
    "# Por reproducibilidad\n",
    "th.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "DC = 'cuda:0' if th.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\93004\\anaconda3\\envs\\Tesis\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# funciones aleatorias\n",
    "import random\n",
    "# tomar n elementos de una secuencia\n",
    "from itertools import islice as take\n",
    "\n",
    "# audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython as ip\n",
    "\n",
    "# redes neuronales\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# redes audio\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "# redes visión\n",
    "# import torchvision.models as tvm\n",
    "\n",
    "# redes neuronales\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchaudio.datasets import SPEECHCOMMANDS\n",
    "# inspección de arquitectura\n",
    "from torchinfo import summary\n",
    "\n",
    "# barras de progreso\n",
    "from tqdm.auto import trange\n",
    "\n",
    "#Counter\n",
    "import collections\n",
    "\n",
    "# Files\n",
    "from os.path import join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import functional as F\n",
    "from torchaudio.transforms import MelSpectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lee el archivo de texto utilizando pd.read_csv()\n",
    "df = pd.read_csv('D:\\\\CommonVoice2\\\\clean_data_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear las categorías de edad a valores numéricos\n",
    "mapeo_edades = {'teens': 18, 'twenties': 20, 'thirties': 35, 'fourties': 45, 'fifties': 55, 'sixties': 65, 'seventies': 75, 'eighties': 80, 'nineties': 90}\n",
    "\n",
    "# Crear una nueva columna 'age_numerico' usando el mapeo\n",
    "df['age_numerico'] = df['age'].replace(mapeo_edades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['gender'] != 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].replace({'male': 0,\n",
    "                                'female': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tamaño de la ventana\n",
    "n_fft = 1024\n",
    "# tamaño del salto\n",
    "hop_length = n_fft // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tamaño del lote\n",
    "BATCH_SIZE = 40\n",
    "\n",
    "# parámetros de audio\n",
    "SECS = 1\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "# parámetros FFT\n",
    "N_FFT = 400\n",
    "HOP_LENGTH = N_FFT // 2\n",
    "\n",
    "# SpeechCommands classes\n",
    "CLASSES_AGE = (\n",
    "    'teens', 'twenties', 'thirties', 'fourties', 'fifties',\n",
    "    'sixties', 'seventies', 'eighties', 'nineties'\n",
    ")\n",
    "\n",
    "CLASSES_GENDER =('male','female')\n",
    "\n",
    "NUM_CLASSES = len(CLASSES_AGE)\n",
    "CLASS_IDX = {c: i for i, c in enumerate(CLASSES_AGE)}\n",
    "print(CLASS_IDX)\n",
    "\n",
    "NUM_CLASSES2 = len(CLASSES_GENDER)\n",
    "CLASS_IDX2 = {c: i for i, c in enumerate(CLASSES_GENDER)}\n",
    "print(CLASS_IDX2)\n",
    "\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    \"\"\"Initializes pseudo-random number generators.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "# reproducibilidad\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES_GEN =len(CLASSES_GENDER)\n",
    "NUM_CLASES_AGE = len(CLASSES_AGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def label2index_age(label):\n",
    "    return CLASS_IDX[label]\n",
    "\n",
    "def label2index_gender(label):\n",
    "    return CLASS_IDX2[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonVoice2(Dataset):\n",
    "\n",
    "    def __init__(self, df, waveform_tsfm=identity, label_tsfm=identity, cut=False, cut_sec=1):\n",
    "        self.waveform_tsfm = waveform_tsfm\n",
    "        self.label_tsfm = label_tsfm\n",
    "        self.df = df\n",
    "        self.cut = cut\n",
    "        self.cut_sec = cut_sec\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # print(i)\n",
    "        dato = self.df.iloc[i]\n",
    "        path = dato['path']\n",
    "        edad = dato['age']\n",
    "        edad_num = dato['age_numerico']\n",
    "        genero = dato['gender']\n",
    "\n",
    "        directorio_actual = os.getcwd()\n",
    "        directorio_actual +='/temp'\n",
    "\n",
    "        audio = AudioFileClip(path)\n",
    "        duracion = audio.duration\n",
    "\n",
    "        if duracion >= self.cut_sec and self.cut:\n",
    "            # CORTAR EL AUDIO\n",
    "            # if self.cut:\n",
    "            start_time = 0  # Tiempo de inicio en segundos\n",
    "\n",
    "            # Realizar el corte\n",
    "            cut_audio = audio.subclip(start_time)\n",
    "            \n",
    "            # Ajustar la duración del audio al valor deseado\n",
    "            dur_audio = cut_audio.set_duration(self.cut_sec)\n",
    "            \n",
    "            # nombre_archivo = 'temp_'+i+'.wav'\n",
    "            # print(nombre_archivo)\n",
    "\n",
    "            # Crear un archivo temporal\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "                temp_path = temp_file.name\n",
    "\n",
    "                # Exportar el audio cortado al archivo temporal\n",
    "                dur_audio.write_audiofile(temp_path,verbose=False, logger=None)\n",
    "\n",
    "                # print(temp_path)\n",
    "\n",
    "                # Cargar la forma de onda del archivo de audio temporal antes de salir del bloque 'with'\n",
    "            waveform, sample_rate = librosa.load(temp_path, sr=16000)\n",
    "            os.remove(temp_path)\n",
    "        else:\n",
    "            waveform, sample_rate = librosa.load(path, sr = 16000)\n",
    "\n",
    "        # print(path)\n",
    "        # waveform, sample_rate, label, *_ = super().__getitem__(i)\n",
    "        x = self.waveform_tsfm(waveform)\n",
    "        # y = self.label_tsfm(label)\n",
    "        return x, edad , genero , edad_num\n",
    "        # return x, edad, genero, edad_num, sample_rate\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveformPadTruncate(nn.Module):\n",
    "\n",
    "    def __init__(self, secs=1, sample_rate=16000, transform_type=0):\n",
    "        super().__init__()\n",
    "        self.samples = secs * sample_rate\n",
    "        self.transform_type=transform_type\n",
    "        self.sample_rate=sample_rate\n",
    "\n",
    "    def forward(self, waveform):\n",
    "        samples = len(waveform)\n",
    "        wave = torch.tensor(waveform, dtype=torch.float32)\n",
    "        waveform = torch.from_numpy(waveform)\n",
    "\n",
    "        if samples < self.samples:\n",
    "          waveform = waveform.unsqueeze(0) if waveform.dim() == 1 else waveform\n",
    "          difference = self.samples - samples\n",
    "          padding = torch.zeros(1, difference)\n",
    "          waveform = torch.cat([waveform, padding], 1)\n",
    "          # print(waveform.shape)\n",
    "          waveform= waveform.squeeze()\n",
    "\n",
    "        elif samples > self.samples:\n",
    "            start = random.randint(0, samples - self.samples)\n",
    "            # Devuelve un nuevo tensor que es una versión reducida del tensor de entrada.\n",
    "            waveform = waveform.narrow(1, start, self.samples) # (dimension, start, length)\n",
    "\n",
    "\n",
    "        if self.transform_type==1:\n",
    "          spectrograma = T.MelSpectrogram(n_fft=n_fft, hop_length=hop_length)(waveform)\n",
    "          spectrograma2 = spectrograma.flatten(start_dim=1)\n",
    "          spectrograma3  = spectrograma.reshape(-1, 1)\n",
    "          # print(spectrograma.shape)\n",
    "          return spectrograma\n",
    "        elif self.transform_type==2:\n",
    "          \n",
    "          # waveform = torch.from_numpy(waveform)\n",
    "          mfcc = T.MFCC(n_mfcc=23,sample_rate=16000)(waveform)\n",
    "          return mfcc\n",
    "        else:\n",
    "          return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_ent, df_val = train_test_split(df,\n",
    "                                  test_size=0.2,\n",
    "                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ent = df_ent.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ent = CommonVoice2(\n",
    "    # directorio de datos\n",
    "    df = df_ent,\n",
    "    # transformación de la forma de onda\n",
    "    waveform_tsfm=WaveformPadTruncate(transform_type=2),\n",
    "    # transformación de etiqueta\n",
    "    label_tsfm=label2index_age,\n",
    "    cut=True,\n",
    "    cut_sec=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_ent= DataLoader(\n",
    "    ds_ent,\n",
    "    # tamaño del lote\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos un Dataset\n",
    "ds_val = CommonVoice2(\n",
    "    # directorio de datos\n",
    "    df = df_val,\n",
    "    # transformación de la forma de onda\n",
    "    waveform_tsfm=WaveformPadTruncate(transform_type=2),\n",
    "    # transformación de etiqueta\n",
    "    label_tsfm=label2index_age,\n",
    "    cut=True,\n",
    "    cut_sec=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_val= DataLoader(\n",
    "    ds_val,\n",
    "    # tamaño del lote\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exactitud(y_hat, y):\n",
    "  cmp = y_hat.argmax(dim=-1) == y\n",
    "  aciertos = th.count_nonzero(cmp)\n",
    "  return aciertos / cmp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paso_ent(modelo,\n",
    "             fp_edades,\n",
    "             fp_genero,\n",
    "             fp_reg,\n",
    "             metrica_edades,\n",
    "             metrica_genero,\n",
    "             metrica_edadN,\n",
    "             opt,\n",
    "             X,\n",
    "             y_edad,\n",
    "             y_genero,\n",
    "             y_reg):\n",
    "  opt.zero_grad() # se ponen los gradientes asociados a los parámetros\n",
    "                    # a actualizaren en cero\n",
    "\n",
    "  y_hat_edad, y_hat_genero, y_hat_reg = modelo(X) # se propagan las entradas para obtener las predicciones\n",
    "\n",
    "  # y_hat_genero = y_hat_genero.squeeze().float()\n",
    "  # y_hat_reg = y_hat_reg.squeeze().float()\n",
    "\n",
    "\n",
    "  # sacamos las probabilidades\n",
    "  y_prob = F.softmax(y_hat_edad, 1)\n",
    "\n",
    "  # sacamos las clases\n",
    "  y_pred = torch.argmax(y_prob, 1).detach().cpu().numpy()\n",
    "\n",
    "  # print(y_pred)\n",
    "  # print(y_hat_edad)\n",
    "\n",
    "  y_pred_genero = torch.round(y_hat_genero)\n",
    "\n",
    "  # y_pred_detached = y_pred.detach()\n",
    "\n",
    "  # perdida = F.cross_entropy(y_hat, y) # se calcula la pérdida\n",
    "  # print('y_hat')\n",
    "  # print(y_hat_edad.dtype)\n",
    "  # print(y_hat_reg.dtype)\n",
    "  # print(y_hat_genero.dtype)\n",
    "  # print('y_')\n",
    "  # print(y_genero.dtype)\n",
    "  # print(y_edad.dtype)\n",
    "  # print(y_reg.dtype)\n",
    "  \n",
    "\n",
    "  perdida_genero = F.binary_cross_entropy(y_hat_genero, y_genero.float()) #fp_edades\n",
    "  perdida_edad = F.cross_entropy(y_hat_edad, y_edad) #fp_genero\n",
    "  perdida_reg = F.mse_loss(y_hat_reg, y_reg.float()) #fp_reg\n",
    "\n",
    "  # print('Perdidas')\n",
    "  # print(perdida_genero.dtype)\n",
    "  # print(perdida_edad.dtype)\n",
    "  # print(perdida_reg.dtype)\n",
    "  # Puedes ajustar los pesos según sea necesario\n",
    "  w_genero = 0.01\n",
    "  w_edad = 0.01\n",
    "  w_reg = 0.01\n",
    "\n",
    "  # print('Pesos')\n",
    "  # print(w_genero.dtype)\n",
    "  # print(w_edad.dtype)\n",
    "  # print(w_reg.dtype)\n",
    "\n",
    "  # Calcular la pérdida total como la suma ponderada de las pérdidas individuales\n",
    "  perdida_total = w_genero * perdida_genero.float() + w_edad * perdida_edad.float() + w_reg * perdida_reg.float()\n",
    "  perdida_total = perdida_total.float()\n",
    "\n",
    "  # print(perdida_total.dtype)\n",
    "\n",
    "  perdida_total.backward() # se obtienen los gradientes\n",
    "  opt.step() # se actualizan todos los parámetros del modelo\n",
    "\n",
    "\n",
    "  with th.no_grad():\n",
    "    perdida_paso = perdida_total.cpu().numpy() # convertimos la pérdida (instancia de\n",
    "                                         # Tensor de orden 0) a NumPy, para\n",
    "                                         # lo que es necesario moverla a CPU\n",
    "    # metricas_paso = metrica(y_hat, y)\n",
    "\n",
    "    metrica_genero_paso = metrica_genero(y_hat_genero, y_genero.float())\n",
    "    metrica_edad_paso = metrica_edades(y_hat_edad, y_edad)\n",
    "    metrica_reg_paso = metrica_edadN(y_hat_reg, y_reg) \n",
    "\n",
    "    weightedf1= f1_score(y_pred_genero.cpu(), y_pred, average='weighted')\n",
    "\n",
    "  # return perdida_paso, metricas_paso\n",
    "  return perdida_paso, metrica_edad_paso, metrica_genero_paso, metrica_reg_paso, weightedf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def entrena(modelo,\n",
    "            fp_edades,\n",
    "            fp_genero,\n",
    "            fp_reg,\n",
    "            metrica_edades,\n",
    "            metrica_genero,\n",
    "            metrica_edadN,\n",
    "            opt,\n",
    "            entdl,\n",
    "            valdl,\n",
    "            disp,\n",
    "            ckptpath,\n",
    "            n_epocas = 10,\n",
    "            tbdir = 'runs/'):\n",
    "  n_lotes_ent = len(entdl)\n",
    "  n_lotes_val = len(valdl)\n",
    "\n",
    "  hist = {'perdida_ent':np.zeros(n_epocas),\n",
    "          'weightedF1_ent': np.zeros(n_epocas),\n",
    "          'weightedF1_val': np.zeros(n_epocas),\n",
    "          'perdida_val': np.zeros(n_epocas),\n",
    "          'Accuracy_Edades_ent': np.zeros(n_epocas),\n",
    "          'Accuracy_Edades_val': np.zeros(n_epocas),\n",
    "\n",
    "          'Accuracy_Genero_ent': np.zeros(n_epocas),\n",
    "          'Accuracy_Genero_val': np.zeros(n_epocas),\n",
    "\n",
    "          'MSE_Edad_ent': np.zeros(n_epocas),\n",
    "          'MSE_Edad_val': np.zeros(n_epocas)}\n",
    "\n",
    "  # tbwriter = SummaryWriter(tbdir)\n",
    "  perdida_min = th.inf\n",
    "  mejor_modelo = copy.deepcopy(modelo)\n",
    "\n",
    "\n",
    "  for e in range(n_epocas):\n",
    "    # bucle de entrenamiento\n",
    "    modelo.train()\n",
    "    for Xlote, ylote_edades, ylote_genero, ylote_reg, *_ in entdl:\n",
    "      Xlote = Xlote.to(disp)\n",
    "      ylote_edades = ylote_edades.to(disp)\n",
    "      ylote_genero = ylote_genero.to(disp)\n",
    "      ylote_reg = ylote_reg.to(disp)\n",
    "\n",
    "      # perdida_paso, perdida_edad_paso, perdida_genero_paso, perdida_reg_paso, weightedf1\n",
    "      perdida_paso, metrica_edad_paso, metrica_genero_paso, metrica_reg_paso, weightedf1 = paso_ent(modelo,\n",
    "                                            fp_edades,\n",
    "                                            fp_genero,\n",
    "                                            fp_reg,\n",
    "                                            metrica_edades,\n",
    "                                            metrica_genero,\n",
    "                                            metrica_edadN,\n",
    "                                            opt,\n",
    "                                            Xlote,\n",
    "                                            ylote_edades,\n",
    "                                            ylote_genero,\n",
    "                                            ylote_reg)\n",
    "\n",
    "      hist['perdida_ent'][e] += perdida_paso\n",
    "      hist['weightedF1_ent'][e] += weightedf1\n",
    "      hist['Accuracy_Edades_ent'][e] += metrica_edad_paso\n",
    "      hist['Accuracy_Genero_ent'][e] += metrica_genero_paso\n",
    "      hist['MSE_Edad_ent'][e] += metrica_reg_paso\n",
    "\n",
    "    # bucle de validación\n",
    "    modelo.eval()\n",
    "    with th.no_grad():\n",
    "      for Xlote, ylote_edades, ylote_genero, ylote_reg, *_  in valdl:\n",
    "        Xlote = Xlote.to(disp)\n",
    "        ylote_edades = ylote_edades.to(disp)\n",
    "        ylote_genero = ylote_genero.to(disp)\n",
    "        ylote_reg = ylote_reg.to(disp)\n",
    "\n",
    "        y_hat_edades, y_hat_genero, y_hat_reg = modelo(Xlote)\n",
    "\n",
    "        y_hat_genero = y_hat_genero.squeeze().float()\n",
    "        y_hat_reg = y_hat_reg.squeeze().float()\n",
    "\n",
    "        # sacamos las probabilidades\n",
    "        y_prob = F.softmax(y_hat_edades, 1)\n",
    "\n",
    "        # sacamos las clases\n",
    "        y_pred = torch.argmax(y_prob, 1)\n",
    "\n",
    "        weightedf1= f1_score(ylote_edades.cpu(), y_pred.cpu().numpy(), average='weighted')\n",
    "\n",
    "        perdida_genero = F.binary_cross_entropy(y_hat_genero, ylote_genero.float()) #fp_edades\n",
    "        perdida_edad = F.cross_entropy(y_hat_edades, ylote_edades) #fp_genero\n",
    "        perdida_reg = F.mse_loss(y_hat_reg, ylote_reg) #fp_reg\n",
    "\n",
    "        # Puedes ajustar los pesos según sea necesario\n",
    "        w_genero = 0.01\n",
    "        w_edad = 0.01\n",
    "        w_reg = 0.01\n",
    "\n",
    "        # Calcular la pérdida total como la suma ponderada de las pérdidas individuales\n",
    "        perdida_total = w_genero * perdida_genero.float() + w_edad * perdida_edad.float() + w_reg * perdida_reg.float()\n",
    "\n",
    "        metrica_genero_val = metrica_genero(y_hat_genero, ylote_genero.float())\n",
    "        metrica_edad_val = metrica_edades(y_hat_edades, ylote_edades)\n",
    "        metrica_reg_val = metrica_edadN(y_hat_reg, ylote_reg)\n",
    "\n",
    "        hist['perdida_val'][e] += perdida_total\n",
    "        hist['weightedF1_val'][e] += weightedf1\n",
    "        hist['Accuracy_Edades_val'][e] += metrica_edad_val\n",
    "        hist['Accuracy_Genero_val'][e] += metrica_genero_val\n",
    "        hist['MSE_Edad_val'][e] += metrica_reg_val\n",
    "\n",
    "    hist['weightedF1_ent'][e] /=  n_lotes_ent\n",
    "    hist['perdida_ent'][e] /=  n_lotes_ent\n",
    "    hist['perdida_ent'][e] =  hist['perdida_ent'][e]*100\n",
    "    hist['Accuracy_Edades_ent'][e] /= n_lotes_ent\n",
    "    hist['Accuracy_Edades_ent'][e] *= 100\n",
    "\n",
    "    hist['Accuracy_Genero_ent'][e] /= n_lotes_ent\n",
    "    hist['Accuracy_Genero_ent'][e] *= 100\n",
    "\n",
    "    hist['MSE_Edad_ent'][e] /= n_lotes_ent\n",
    "    hist['MSE_Edad_ent'][e] *= 100\n",
    "\n",
    "\n",
    "    hist['weightedF1_val'][e] /=  n_lotes_val\n",
    "    hist['perdida_val'][e] /=  n_lotes_val\n",
    "    hist['perdida_val'][e] =  hist['perdida_val'][e]*100\n",
    "\n",
    "    hist['Accuracy_Edades_val'][e] /= n_lotes_val\n",
    "    hist['Accuracy_Edades_val'][e] *= 100\n",
    "\n",
    "    hist['Accuracy_Genero_val'][e] /= n_lotes_val\n",
    "    hist['Accuracy_Genero_val'][e] *= 100\n",
    "\n",
    "    hist['MSE_Edad_val'][e] /= n_lotes_val\n",
    "    hist['MSE_Edad_val'][e] *= 100\n",
    "    # guardamos checkpoint y copiamos pesos y sesgos del modelo\n",
    "    # actual si disminuye la metrica a monitorear\n",
    "    if hist['perdida_val'][e] < perdida_min:\n",
    "      mejor_modelo.load_state_dict(modelo.state_dict())\n",
    "      guarda_ckpt(ckptpath, modelo, e, opt)\n",
    "\n",
    "    # registra_info_tboard(tbwriter, e, hist)\n",
    "\n",
    "    print(f'\\nÉpoca {e}:\\n '\n",
    "          'ENTRENAMIENTO: \\n'\n",
    "          f'weighted_F1(E) = {hist[\"weightedF1_ent\"][e]:.3f},\\n '\n",
    "          f'Perdida(E) = {hist[\"perdida_ent\"][e]:.3f}, \\n'\n",
    "          f'Accuracy_Edades(E) = {hist[\"Accuracy_Edades_ent\"][e]:.3f},\\n '\n",
    "          f'Accuracy_Genero(E) = {hist[\"Accuracy_Genero_ent\"][e]:.3f},\\n'\n",
    "          f'MSE_Edad(E) = {hist[\"MSE_Edad_ent\"][e]:.3f},\\n '\n",
    "          'VALIDACIÓN: \\n'\n",
    "          f'weighted_F1(V) = {hist[\"weightedF1_val\"][e]:.3f},\\n  '\n",
    "          f'Perdida(V) = {hist[\"perdida_val\"][e]:.3f},\\n  '\n",
    "          f'Accuracy_Edades(V) = {hist[\"Accuracy_Edades_val\"][e]:.3f}\\n '\n",
    "          f'Accuracy_Genero(V) = {hist[\"Accuracy_Genero_val\"][e]:.3f}\\n '\n",
    "          f'MSE_Edad(V) = {hist[\"MSE_Edad_val\"][e]:.3f}\\n '\n",
    "          '---------------------------------------------------------------------')\n",
    "\n",
    "  return modelo, mejor_modelo, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DC = 'cuda:1' if th.cuda.is_available() else 'cpu'\n",
    "LOGDIR = './logs/'\n",
    "N_EPOCAS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrotEnd(nn.Module):\n",
    "    def __init__(self,dim_inicial, clases_age=NUM_CLASES_AGE, dropout=0.0, extract=False):\n",
    "        super(FrotEnd, self).__init__()\n",
    "\n",
    "        self.age_classification = nn.Sequential(\n",
    "            nn.Linear(dim_inicial,dim_inicial),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(dim_inicial),\n",
    "            nn.Linear(dim_inicial,clases_age),\n",
    "            # nn.Softmax()\n",
    "        )\n",
    "\n",
    "        self.gender = nn.Sequential(\n",
    "            nn.Linear(dim_inicial,dim_inicial),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(dim_inicial),\n",
    "            nn.Linear(dim_inicial,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.age_regression = nn.Sequential(\n",
    "            nn.Linear(dim_inicial,dim_inicial),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(dim_inicial),\n",
    "            nn.Linear(dim_inicial,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        age_classes = self.age_classification(x)\n",
    "        age_classes = age_classes\n",
    "        # age_classes = age_classes.float()\n",
    "        \n",
    "        gender = self.gender(x)\n",
    "        gender = gender.squeeze().float()\n",
    "\n",
    "        age_regression = self.age_regression(x)\n",
    "        age_regression = age_regression.squeeze().float()\n",
    "\n",
    "        return age_classes , gender , age_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDvector(nn.Module):\n",
    "    \"\"\"LSTM-based d-vector.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size,embedding_size, num_layers=1):\n",
    "        super(LSTMDvector, self).__init__()\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Capa lineal para obtener el d-vector\n",
    "        self.linear = nn.Linear(hidden_size, embedding_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device) \n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n",
    "\n",
    "        lstm_out1, _ = self.lstm1(x, (h0, c0))\n",
    "        lstm_out2, _ = self.lstm2(lstm_out1)\n",
    "        lstm_out3, _ = self.lstm3(lstm_out2)\n",
    "\n",
    "        # Tomar la última salida de la secuencia como d-vector\n",
    "        d_vector = self.linear(lstm_out3[:, -1, :])\n",
    "\n",
    "        class_edad, genero, edad_num = self.frontEnd(d_vector)\n",
    "\n",
    "        return class_edad.float(), genero.float(), edad_num.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_layer = LSTMDvector(16000)\n",
    "summary(test_layer, (40, 1,16000), device='cpu',col_names=['input_size', 'output_size', 'num_params'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
