{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "import wandb\n",
    "\n",
    "# import speechbrain as sb\n",
    "# from speechbrain.lobes.models.Xvector import Xvector\n",
    "\n",
    "\n",
    "# Por reproducibilidad\n",
    "th.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "DC = 'cuda:1' if th.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchinfo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# from torchaudio.datasets import SPEECHCOMMANDS\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# inspección de arquitectura\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchinfo\u001b[39;00m \u001b[39mimport\u001b[39;00m summary\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# barras de progreso\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m trange\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchinfo'"
     ]
    }
   ],
   "source": [
    "# funciones aleatorias\n",
    "import random\n",
    "# tomar n elementos de una secuencia\n",
    "from itertools import islice as take\n",
    "\n",
    "# audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython as ip\n",
    "\n",
    "# redes neuronales\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# redes audio\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "# redes visión\n",
    "# import torchvision.models as tvm\n",
    "\n",
    "# redes neuronales\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchaudio.datasets import SPEECHCOMMANDS\n",
    "# inspección de arquitectura\n",
    "from torchinfo import summary\n",
    "\n",
    "# barras de progreso\n",
    "from tqdm.auto import trange\n",
    "\n",
    "#Counter\n",
    "import collections\n",
    "\n",
    "# Files\n",
    "from os.path import join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import functional as F\n",
    "# from torchaudio.transforms import MelSpectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guarda_ckpt(ckptpath, modelo, epoca, opt):\n",
    "  estado_modelo = {'epoch': epoca,\n",
    "                   'model_state_dict': modelo.state_dict(),\n",
    "                   'optimizer_state_dict': opt.state_dict()}\n",
    "  th.save(estado_modelo, ckptpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lee el archivo de texto utilizando pd.read_csv()\n",
    "# df_Common = pd.read_csv('../../../../../../media/ar/Expansion/CommonVoice2/clean_data_all.csv')\n",
    "df_Timit = pd.read_csv(\"./data/train_data_gender.csv\")\n",
    "df_CCv2 = pd.read_csv('./audios_CCV2_Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Common['path'] = df_Common['path'].replace(to_replace=r'^D:/', value='../../../../../../media/ar/Expansion/', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mapear las categorías de edad a valores numéricos\n",
    "# mapeo_edades = {'teens': 18, 'twenties': 20, 'thirties': 35, 'fourties': 45, 'fifties': 55, 'sixties': 65, 'seventies': 75, 'eighties': 80, 'nineties': 90}\n",
    "\n",
    "# # Crear una nueva columna 'age_numerico' usando el mapeo\n",
    "# df_Common['age_numerico'] = df_Common['age'].replace(mapeo_edades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Common = df_Common[df_Common['gender'] != 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Common['gender'] = df_Common['gender'].replace({'male': 0,\n",
    "#                                 'female': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tamaño de la ventana\n",
    "n_fft = 1024\n",
    "# tamaño del salto\n",
    "hop_length = n_fft // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI681.WAV.wav</td>\n",
       "      <td>data/data/TRAIN/DR4/MMDM0/SI681.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.WAV.wav</td>\n",
       "      <td>data/data/TRAIN/DR4/MMDM0/SI1311.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX141.WAV.wav</td>\n",
       "      <td>data/data/TRAIN/DR4/MMDM0/SX141.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX141.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX51.WAV.wav</td>\n",
       "      <td>data/data/TRAIN/DR4/MMDM0/SX51.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX51.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX411.WAV.wav</td>\n",
       "      <td>data/data/TRAIN/DR4/MMDM0/SX411.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX411.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index test_or_train dialect_region speaker_id        filename  \\\n",
       "0    1.0         TRAIN            DR4      MMDM0   SI681.WAV.wav   \n",
       "1    7.0         TRAIN            DR4      MMDM0  SI1311.WAV.wav   \n",
       "2   11.0         TRAIN            DR4      MMDM0   SX141.WAV.wav   \n",
       "3   14.0         TRAIN            DR4      MMDM0    SX51.WAV.wav   \n",
       "4   24.0         TRAIN            DR4      MMDM0   SX411.WAV.wav   \n",
       "\n",
       "                         path_from_data_dir  \\\n",
       "0   data/data/TRAIN/DR4/MMDM0/SI681.WAV.wav   \n",
       "1  data/data/TRAIN/DR4/MMDM0/SI1311.WAV.wav   \n",
       "2   data/data/TRAIN/DR4/MMDM0/SX141.WAV.wav   \n",
       "3    data/data/TRAIN/DR4/MMDM0/SX51.WAV.wav   \n",
       "4   data/data/TRAIN/DR4/MMDM0/SX411.WAV.wav   \n",
       "\n",
       "          path_from_data_dir_windows  is_converted_audio  is_audio  \\\n",
       "0   TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav                True      True   \n",
       "1  TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WAV.wav                True      True   \n",
       "2   TRAIN\\\\DR4\\\\MMDM0\\\\SX141.WAV.wav                True      True   \n",
       "3    TRAIN\\\\DR4\\\\MMDM0\\\\SX51.WAV.wav                True      True   \n",
       "4   TRAIN\\\\DR4\\\\MMDM0\\\\SX411.WAV.wav                True      True   \n",
       "\n",
       "   is_word_file  is_phonetic_file  is_sentence_file  gender  \n",
       "0         False             False             False       0  \n",
       "1         False             False             False       0  \n",
       "2         False             False             False       0  \n",
       "3         False             False             False       0  \n",
       "4         False             False             False       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Timit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'teens': 0, 'twenties': 1, 'thirties': 2, 'fourties': 3, 'fifties': 4, 'sixties': 5, 'seventies': 6, 'eighties': 7}\n",
      "{'male': 0, 'female': 1}\n"
     ]
    }
   ],
   "source": [
    "# tamaño del lote\n",
    "BATCH_SIZE = 40\n",
    "\n",
    "# parámetros de audio\n",
    "SECS = 1\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "# parámetros FFT\n",
    "N_FFT = 400\n",
    "HOP_LENGTH = N_FFT // 2\n",
    "\n",
    "# SpeechCommands classes\n",
    "CLASSES_AGE = (\n",
    "    'teens', 'twenties', 'thirties', 'fourties', 'fifties',\n",
    "    'sixties', 'seventies', 'eighties'\n",
    ")\n",
    "\n",
    "CLASSES_GENDER =('male','female')\n",
    "\n",
    "NUM_CLASSES = len(CLASSES_AGE)\n",
    "CLASS_IDX = {c: i for i, c in enumerate(CLASSES_AGE)}\n",
    "print(CLASS_IDX)\n",
    "\n",
    "NUM_CLASSES2 = len(CLASSES_GENDER)\n",
    "CLASS_IDX2 = {c: i for i, c in enumerate(CLASSES_GENDER)}\n",
    "print(CLASS_IDX2)\n",
    "\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    \"\"\"Initializes pseudo-random number generators.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "# reproducibilidad\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES_GEN =len(CLASSES_GENDER)\n",
    "NUM_CLASES_AGE = len(CLASSES_AGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def label2index_age(label):\n",
    "    return CLASS_IDX[label]\n",
    "\n",
    "def label2index_gender(label):\n",
    "    return CLASS_IDX2[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TIMIT(Dataset):\n",
    "\n",
    "    def __init__(self, df, waveform_tsfm=identity, label_tsfm=identity, cut=False, cut_sec=1):\n",
    "        self.waveform_tsfm = waveform_tsfm\n",
    "        self.label_tsfm = label_tsfm\n",
    "        self.df = df\n",
    "        self.cut = cut\n",
    "        self.cut_sec = cut_sec\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # print(i)\n",
    "        dato = self.df.iloc[i]\n",
    "        path = dato['path_from_data_dir']\n",
    "        genero = dato['gender']\n",
    "\n",
    "        directorio_actual = os.getcwd()\n",
    "        directorio_actual +='/temp'\n",
    "\n",
    "        audio = AudioFileClip(path)\n",
    "        duracion = audio.duration\n",
    "\n",
    "        if duracion >= self.cut_sec and self.cut:\n",
    "            # CORTAR EL AUDIO\n",
    "            # if self.cut:\n",
    "            start_time = 0  # Tiempo de inicio en segundos\n",
    "\n",
    "            # Realizar el corte\n",
    "            cut_audio = audio.subclip(start_time)\n",
    "            \n",
    "            # Ajustar la duración del audio al valor deseado\n",
    "            dur_audio = cut_audio.set_duration(self.cut_sec)\n",
    "            \n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "                temp_path = temp_file.name\n",
    "\n",
    "                # Exportar el audio cortado al archivo temporal\n",
    "                dur_audio.write_audiofile(temp_path,verbose=False, logger=None)\n",
    "\n",
    "            waveform, sample_rate = librosa.load(temp_path, sr=16000)\n",
    "            os.remove(temp_path)\n",
    "        else:\n",
    "            waveform, sample_rate = librosa.load(path, sr = 16000)\n",
    "\n",
    "        x = self.waveform_tsfm(waveform)\n",
    "        return x , genero \n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCV2(Dataset):\n",
    "\n",
    "    def __init__(self, df, waveform_tsfm=identity, label_tsfm=identity, cut=False, cut_sec=1):\n",
    "        self.waveform_tsfm = waveform_tsfm\n",
    "        self.label_tsfm = label_tsfm\n",
    "        self.df = df\n",
    "        self.cut = cut\n",
    "        self.cut_sec = cut_sec\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # print(i)\n",
    "        dato = self.df.iloc[i]\n",
    "        path = dato['file_path']\n",
    "        edad = dato['age_group']\n",
    "        edad_num = dato['age']\n",
    "        genero = dato['gender']\n",
    "\n",
    "        directorio_actual = os.getcwd()\n",
    "        directorio_actual +='/temp'\n",
    "\n",
    "        audio = AudioFileClip(path)\n",
    "        duracion = audio.duration\n",
    "\n",
    "        if duracion >= self.cut_sec and self.cut:\n",
    "            # CORTAR EL AUDIO\n",
    "            # if self.cut:\n",
    "            start_time = 0  # Tiempo de inicio en segundos\n",
    "\n",
    "            # Realizar el corte\n",
    "            cut_audio = audio.subclip(start_time)\n",
    "            \n",
    "            # Ajustar la duración del audio al valor deseado\n",
    "            dur_audio = cut_audio.set_duration(self.cut_sec)\n",
    "        \n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "                temp_path = temp_file.name\n",
    "\n",
    "                # Exportar el audio cortado al archivo temporal\n",
    "                dur_audio.write_audiofile(temp_path,verbose=False, logger=None)\n",
    "\n",
    "            waveform, sample_rate = librosa.load(temp_path, sr=16000)\n",
    "            os.remove(temp_path)\n",
    "        else:\n",
    "            waveform, sample_rate = librosa.load(path, sr = 16000)\n",
    "\n",
    "        x = self.waveform_tsfm(waveform)\n",
    "        # y = self.label_tsfm(label)\n",
    "        return x, edad , genero , edad_num\n",
    "        # return x, edad, genero, edad_num, sample_rate\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonVoice2(Dataset):\n",
    "\n",
    "    def __init__(self, df, waveform_tsfm=identity, label_tsfm=identity, cut=False, cut_sec=1):\n",
    "        self.waveform_tsfm = waveform_tsfm\n",
    "        self.label_tsfm = label_tsfm\n",
    "        self.df = df\n",
    "        self.cut = cut\n",
    "        self.cut_sec = cut_sec\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # print(i)\n",
    "        dato = self.df.iloc[i]\n",
    "        path = dato['path']\n",
    "        edad = dato['age']\n",
    "        edad_num = dato['age_numerico']\n",
    "        genero = dato['gender']\n",
    "\n",
    "        directorio_actual = os.getcwd()\n",
    "        directorio_actual +='/temp'\n",
    "\n",
    "        audio = AudioFileClip(path)\n",
    "        duracion = audio.duration\n",
    "\n",
    "        if duracion >= self.cut_sec and self.cut:\n",
    "            # CORTAR EL AUDIO\n",
    "            # if self.cut:\n",
    "            start_time = 0  # Tiempo de inicio en segundos\n",
    "\n",
    "            # Realizar el corte\n",
    "            cut_audio = audio.subclip(start_time)\n",
    "            \n",
    "            # Ajustar la duración del audio al valor deseado\n",
    "            dur_audio = cut_audio.set_duration(self.cut_sec)\n",
    "            \n",
    "            # Crear un archivo temporal\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "                temp_path = temp_file.name\n",
    "\n",
    "                # Exportar el audio cortado al archivo temporal\n",
    "                dur_audio.write_audiofile(temp_path,verbose=False, logger=None)\n",
    "\n",
    "                # print(temp_path)\n",
    "\n",
    "                # Cargar la forma de onda del archivo de audio temporal antes de salir del bloque 'with'\n",
    "            waveform, sample_rate = librosa.load(temp_path, sr=16000)\n",
    "            os.remove(temp_path)\n",
    "        else:\n",
    "            waveform, sample_rate = librosa.load(path, sr = 16000)\n",
    "\n",
    "        # print(path)\n",
    "        # waveform, sample_rate, label, *_ = super().__getitem__(i)\n",
    "        x = self.waveform_tsfm(waveform)\n",
    "        # y = self.label_tsfm(label)\n",
    "        return x, edad , genero , edad_num\n",
    "        # return x, edad, genero, edad_num, sample_rate\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveformPadTruncate(nn.Module):\n",
    "\n",
    "    def __init__(self, secs=1, sample_rate=16000, transform_type=0):\n",
    "        super().__init__()\n",
    "        self.samples = secs * sample_rate\n",
    "        self.transform_type=transform_type\n",
    "        self.sample_rate=sample_rate\n",
    "\n",
    "    def forward(self, waveform):\n",
    "        samples = len(waveform)\n",
    "        wave = torch.tensor(waveform, dtype=torch.float32)\n",
    "        waveform = torch.from_numpy(waveform)\n",
    "\n",
    "        if samples < self.samples:\n",
    "          waveform = waveform.unsqueeze(0) if waveform.dim() == 1 else waveform\n",
    "          difference = self.samples - samples\n",
    "          padding = torch.zeros(1, difference)\n",
    "          waveform = torch.cat([waveform, padding], 1)\n",
    "          # print(waveform.shape)\n",
    "          waveform= waveform\n",
    "          # waveform= waveform.squeeze()\n",
    "\n",
    "        elif samples > self.samples:\n",
    "            start = random.randint(0, samples - self.samples)\n",
    "            # Devuelve un nuevo tensor que es una versión reducida del tensor de entrada.\n",
    "            waveform = waveform.narrow(1, start, self.samples) # (dimension, start, length)\n",
    "\n",
    "\n",
    "        if self.transform_type==1:\n",
    "          spectrograma = T.MelSpectrogram(n_fft=n_fft, hop_length=512)(waveform)\n",
    "          spectrograma2 = spectrograma.flatten(start_dim=1)\n",
    "          spectrograma3  = spectrograma.reshape(-1, 1)\n",
    "          # print(spectrograma.shape)\n",
    "          return spectrograma\n",
    "        elif self.transform_type==2:\n",
    "          \n",
    "          # waveform = torch.from_numpy(waveform)\n",
    "          mfcc = T.MFCC(n_mfcc=23,sample_rate=16000)(waveform)\n",
    "          return mfcc\n",
    "        else:\n",
    "          return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_ent, df_val = train_test_split(df_Timit,\n",
    "                                  test_size=0.2,\n",
    "                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ent = df_ent.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ent = TIMIT(\n",
    "    # directorio de datos\n",
    "    df = df_ent,\n",
    "    # transformación de la forma de onda\n",
    "    waveform_tsfm=WaveformPadTruncate(transform_type=2),\n",
    "    # transformación de etiqueta\n",
    "    label_tsfm=label2index_age,\n",
    "    cut=True,\n",
    "    cut_sec=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_ent= DataLoader(\n",
    "    ds_ent,\n",
    "    # tamaño del lote\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos un Dataset\n",
    "ds_val = TIMIT(\n",
    "    # directorio de datos\n",
    "    df = df_val,\n",
    "    # transformación de la forma de onda\n",
    "    waveform_tsfm=WaveformPadTruncate(transform_type=2),\n",
    "    # transformación de etiqueta\n",
    "    label_tsfm=label2index_age,\n",
    "    cut=True,\n",
    "    cut_sec=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_val= DataLoader(\n",
    "    ds_val,\n",
    "    # tamaño del lote\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exactitud(y_hat, y):\n",
    "  cmp = y_hat.argmax(dim=-1) == y\n",
    "  aciertos = th.count_nonzero(cmp)\n",
    "  return aciertos / cmp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paso_ent_Timit(modelo,\n",
    "             fp_edades,\n",
    "             fp_genero,\n",
    "             fp_reg,\n",
    "             metrica_edades,\n",
    "             metrica_genero,\n",
    "             metrica_edadN,\n",
    "             opt,\n",
    "             X,\n",
    "             y_genero):\n",
    "  opt.zero_grad() # se ponen los gradientes asociados a los parámetros\n",
    "                    # a actualizaren en cero\n",
    "\n",
    "  y_hat_genero = modelo(X) # se propagan las entradas para obtener las predicciones\n",
    "\n",
    "  y_pred_genero = torch.round(y_hat_genero)\n",
    "\n",
    "\n",
    "  perdida_genero = F.binary_cross_entropy(y_hat_genero, y_genero.float()) #fp_edades\n",
    "  # perdida_edad = F.cross_entropy(y_hat_edad, y_edad) #fp_genero\n",
    "  # perdida_reg = F.mse_loss(y_hat_reg, y_reg.float()) #fp_reg\n",
    "\n",
    "  w_genero = 0.01\n",
    "  w_edad = 0.00\n",
    "  w_reg = 0.00\n",
    "\n",
    "\n",
    "  # Calcular la pérdida total como la suma ponderada de las pérdidas individuales\n",
    "  perdida_total = perdida_genero.float()\n",
    "  # perdida_total = w_genero * perdida_genero.float() + w_edad * perdida_edad.float() + w_reg * perdida_reg.float()\n",
    "  perdida_total = perdida_total.float()\n",
    "\n",
    "  # print(perdida_total.dtype)\n",
    "\n",
    "  perdida_total.backward() # se obtienen los gradientes\n",
    "  opt.step() # se actualizan todos los parámetros del modelo\n",
    "\n",
    "\n",
    "  with th.no_grad():\n",
    "    perdida_paso = perdida_total.cpu().numpy() # convertimos la pérdida (instancia de\n",
    "                                         # Tensor de orden 0) a NumPy, para\n",
    "                                         # lo que es necesario moverla a CPU\n",
    "\n",
    "    metrica_genero_paso = metrica_genero(y_hat_genero, y_genero.float())\n",
    "   \n",
    "  return perdida_paso, metrica_genero_paso\n",
    "  # return perdida_paso, metrica_edad_paso, metrica_genero_paso, metrica_reg_paso, weightedf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paso_ent(modelo,\n",
    "             fp_edades,\n",
    "             fp_genero,\n",
    "             fp_reg,\n",
    "             metrica_edades,\n",
    "             metrica_genero,\n",
    "             metrica_edadN,\n",
    "             opt,\n",
    "             X,\n",
    "             y_edad,\n",
    "             y_genero,\n",
    "             y_reg):\n",
    "  opt.zero_grad() # se ponen los gradientes asociados a los parámetros\n",
    "                    # a actualizaren en cero\n",
    "\n",
    "  y_hat_edad, y_hat_genero, y_hat_reg = modelo(X) # se propagan las entradas para obtener las predicciones\n",
    "\n",
    "  # y_hat_genero = y_hat_genero.squeeze().float()\n",
    "  # y_hat_reg = y_hat_reg.squeeze().float()\n",
    "\n",
    "\n",
    "  # sacamos las probabilidades\n",
    "  y_prob = F.softmax(y_hat_edad, 1)\n",
    "\n",
    "  # sacamos las clases\n",
    "  y_pred = torch.argmax(y_prob, 1).detach().cpu().numpy()\n",
    "\n",
    "  # print(y_pred)\n",
    "  # print(y_hat_edad)\n",
    "\n",
    "  y_pred_genero = torch.round(y_hat_genero)\n",
    "\n",
    "  # y_pred_detached = y_pred.detach()\n",
    "\n",
    "  # perdida = F.cross_entropy(y_hat, y) # se calcula la pérdida\n",
    "  # print('y_hat')\n",
    "  # print(y_hat_edad.dtype)\n",
    "  # print(y_hat_reg.dtype)\n",
    "  # print(y_hat_genero.dtype)\n",
    "  # print('y_')\n",
    "  # print(y_genero.dtype)\n",
    "  # print(y_edad.dtype)\n",
    "  # print(y_reg.dtype)\n",
    "  \n",
    "\n",
    "  perdida_genero = F.binary_cross_entropy(y_hat_genero, y_genero.float()) #fp_edades\n",
    "  perdida_edad = F.cross_entropy(y_hat_edad, y_edad) #fp_genero\n",
    "  perdida_reg = F.mse_loss(y_hat_reg, y_reg.float()) #fp_reg\n",
    "\n",
    "  # print('Perdidas')\n",
    "  # print(perdida_genero.dtype)\n",
    "  # print(perdida_edad.dtype)\n",
    "  # print(perdida_reg.dtype)\n",
    "  # Puedes ajustar los pesos según sea necesario\n",
    "  w_genero = 1.0\n",
    "  w_edad = 1.0\n",
    "  w_reg = 1.0\n",
    "\n",
    "  # print('Pesos')\n",
    "  # print(w_genero.dtype)\n",
    "  # print(w_edad.dtype)\n",
    "  # print(w_reg.dtype)\n",
    "\n",
    "  # Calcular la pérdida total como la suma ponderada de las pérdidas individuales\n",
    "  perdida_total = w_genero * perdida_genero.float() + w_edad * perdida_edad.float() + w_reg * perdida_reg.float()\n",
    "  perdida_total = perdida_total.float()\n",
    "\n",
    "  # print(perdida_total.dtype)\n",
    "\n",
    "  perdida_total.backward() # se obtienen los gradientes\n",
    "  opt.step() # se actualizan todos los parámetros del modelo\n",
    "\n",
    "\n",
    "  with th.no_grad():\n",
    "    perdida_paso = perdida_total.cpu().numpy() # convertimos la pérdida (instancia de\n",
    "                                         # Tensor de orden 0) a NumPy, para\n",
    "                                         # lo que es necesario moverla a CPU\n",
    "    # metricas_paso = metrica(y_hat, y)\n",
    "\n",
    "    metrica_genero_paso = metrica_genero(y_hat_genero, y_genero.float())\n",
    "    metrica_edad_paso = metrica_edades(y_hat_edad, y_edad)\n",
    "    metrica_reg_paso = metrica_edadN(y_hat_reg, y_reg) \n",
    "\n",
    "    weightedf1= f1_score(y_pred_genero.cpu(), y_pred, average='weighted')\n",
    "\n",
    "  # return perdida_paso, metricas_paso\n",
    "  return perdida_paso, metrica_edad_paso, metrica_genero_paso, metrica_reg_paso, weightedf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def entrena_Timit(modelo,\n",
    "            fp_edades,\n",
    "            fp_genero,\n",
    "            fp_reg,\n",
    "            metrica_edades,\n",
    "            metrica_genero,\n",
    "            metrica_edadN,\n",
    "            opt,\n",
    "            entdl,\n",
    "            valdl,\n",
    "            disp,\n",
    "            ckptpath,\n",
    "            n_epocas = 10,\n",
    "            tbdir = 'runs/'):\n",
    "  n_lotes_ent = len(entdl)\n",
    "  n_lotes_val = len(valdl)\n",
    "\n",
    "  hist = {'perdida_ent':np.zeros(n_epocas),\n",
    "          # 'weightedF1_ent': np.zeros(n_epocas),\n",
    "          # 'weightedF1_val': np.zeros(n_epocas),\n",
    "          'perdida_val': np.zeros(n_epocas),\n",
    "          # 'Accuracy_Edades_ent': np.zeros(n_epocas),\n",
    "          # 'Accuracy_Edades_val': np.zeros(n_epocas),\n",
    "\n",
    "          'Accuracy_Genero_ent': np.zeros(n_epocas),\n",
    "          'Accuracy_Genero_val': np.zeros(n_epocas)}\n",
    "\n",
    "          # 'MSE_Edad_ent': np.zeros(n_epocas),\n",
    "          # 'MSE_Edad_val': np.zeros(n_epocas)}\n",
    "\n",
    "  # tbwriter = SummaryWriter(tbdir)\n",
    "  perdida_min = th.inf\n",
    "  mejor_modelo = copy.deepcopy(modelo)\n",
    "\n",
    "\n",
    "  for e in range(n_epocas):\n",
    "    # bucle de entrenamiento\n",
    "    modelo.train()\n",
    "    for Xlote, ylote_genero, *_ in entdl:\n",
    "      Xlote = Xlote.to(disp)\n",
    "      # ylote_edades = ylote_edades.to(disp)\n",
    "      ylote_genero = ylote_genero.to(disp)\n",
    "      # ylote_reg = ylote_reg.to(disp)\n",
    "\n",
    "      # perdida_paso, perdida_edad_paso, perdida_genero_paso, perdida_reg_paso, weightedf1\n",
    "      perdida_paso, metrica_genero_paso = paso_ent_Timit(modelo,\n",
    "                                            fp_edades,\n",
    "                                            fp_genero,\n",
    "                                            fp_reg,\n",
    "                                            metrica_edades,\n",
    "                                            metrica_genero,\n",
    "                                            metrica_edadN,\n",
    "                                            opt,\n",
    "                                            Xlote,\n",
    "                                            ylote_genero)\n",
    "\n",
    "      hist['perdida_ent'][e] += perdida_paso\n",
    "      # hist['weightedF1_ent'][e] += weightedf1\n",
    "      # hist['Accuracy_Edades_ent'][e] += metrica_edad_paso\n",
    "      hist['Accuracy_Genero_ent'][e] += metrica_genero_paso\n",
    "      # hist['MSE_Edad_ent'][e] += metrica_reg_paso\n",
    "\n",
    "    # bucle de validación\n",
    "    modelo.eval()\n",
    "    with th.no_grad():\n",
    "      for Xlote, ylote_genero, *_  in valdl:\n",
    "        Xlote = Xlote.to(disp)\n",
    "        # ylote_edades = ylote_edades.to(disp)\n",
    "        ylote_genero = ylote_genero.to(disp)\n",
    "        # ylote_reg = ylote_reg.to(disp)\n",
    "\n",
    "        y_hat_genero = modelo(Xlote)\n",
    "\n",
    "        y_hat_genero = y_hat_genero.squeeze().float()\n",
    "        # y_hat_reg = y_hat_reg.squeeze().float()\n",
    "\n",
    "        # sacamos las probabilidades\n",
    "        # y_prob = F.softmax(y_hat_edades, 1)\n",
    "\n",
    "        # sacamos las clases\n",
    "        # y_pred = torch.argmax(y_prob, 1)\n",
    "\n",
    "        # weightedf1= f1_score(ylote_edades.cpu(), y_pred.cpu().numpy(), average='weighted')\n",
    "\n",
    "        perdida_genero = F.binary_cross_entropy(y_hat_genero, ylote_genero.float()) #fp_edades\n",
    "        # perdida_edad = F.cross_entropy(y_hat_edades, ylote_edades) #fp_genero\n",
    "        # perdida_reg = F.mse_loss(y_hat_reg, ylote_reg) #fp_reg\n",
    "\n",
    "        # Puedes ajustar los pesos según sea necesario\n",
    "        w_genero = 0.01\n",
    "        w_edad = 0.01\n",
    "        w_reg = 0.01\n",
    "\n",
    "        # Calcular la pérdida total como la suma ponderada de las pérdidas individuales\n",
    "        perdida_total = perdida_genero.float()\n",
    "        # perdida_total = w_genero * perdida_genero.float() + w_edad * perdida_edad.float() + w_reg * perdida_reg.float()\n",
    "\n",
    "        metrica_genero_val = metrica_genero(y_hat_genero, ylote_genero.float())\n",
    "        # metrica_edad_val = metrica_edades(y_hat_edades, ylote_edades)\n",
    "        # metrica_reg_val = metrica_edadN(y_hat_reg, ylote_reg)\n",
    "\n",
    "        hist['perdida_val'][e] += perdida_total\n",
    "        # hist['weightedF1_val'][e] += weightedf1\n",
    "        # hist['Accuracy_Edades_val'][e] += metrica_edad_val\n",
    "        hist['Accuracy_Genero_val'][e] += metrica_genero_val\n",
    "        # hist['MSE_Edad_val'][e] += metrica_reg_val\n",
    "\n",
    "    # hist['weightedF1_ent'][e] /=  n_lotes_ent\n",
    "    hist['perdida_ent'][e] /=  n_lotes_ent\n",
    "    hist['perdida_ent'][e] =  hist['perdida_ent'][e]*100\n",
    "    # hist['Accuracy_Edades_ent'][e] /= n_lotes_ent\n",
    "    # hist['Accuracy_Edades_ent'][e] *= 100\n",
    "\n",
    "    hist['Accuracy_Genero_ent'][e] /= n_lotes_ent\n",
    "    hist['Accuracy_Genero_ent'][e] *= 100\n",
    "\n",
    "    # hist['MSE_Edad_ent'][e] /= n_lotes_ent\n",
    "    # hist['MSE_Edad_ent'][e] *= 100\n",
    "\n",
    "\n",
    "    # hist['weightedF1_val'][e] /=  n_lotes_val\n",
    "    hist['perdida_val'][e] /=  n_lotes_val\n",
    "    hist['perdida_val'][e] =  hist['perdida_val'][e]*100\n",
    "\n",
    "    # hist['Accuracy_Edades_val'][e] /= n_lotes_val\n",
    "    # hist['Accuracy_Edades_val'][e] *= 100\n",
    "\n",
    "    hist['Accuracy_Genero_val'][e] /= n_lotes_val\n",
    "    hist['Accuracy_Genero_val'][e] *= 100\n",
    "\n",
    "    # hist['MSE_Edad_val'][e] /= n_lotes_val\n",
    "    # hist['MSE_Edad_val'][e] *= 100\n",
    "    # guardamos checkpoint y copiamos pesos y sesgos del modelo\n",
    "    # actual si disminuye la metrica a monitorear\n",
    "    if hist['perdida_val'][e] < perdida_min:\n",
    "      mejor_modelo.load_state_dict(modelo.state_dict())\n",
    "      guarda_ckpt(ckptpath, modelo, e, opt)\n",
    "\n",
    "    # registra_info_tboard(tbwriter, e, hist)\n",
    "\n",
    "    \n",
    "    wandb.log({\"Validation_acc_genero\": hist[\"Accuracy_Genero_val\"][e],\n",
    "                \"Validation_loss_total\": hist[\"perdida_val\"][e] })\n",
    "    \n",
    "    wandb.log({\"Train_acc_genero\": hist[\"Accuracy_Genero_ent\"][e], \n",
    "                \"Train_loss_total\": hist[\"perdida_ent\"][e] })\n",
    "\n",
    "    print(f'\\nÉpoca {e}:\\n '\n",
    "          'ENTRENAMIENTO: \\n'\n",
    "          # f'weighted_F1(E) = {hist[\"weightedF1_ent\"][e]:.3f},\\n '\n",
    "          f'Perdida(E) = {hist[\"perdida_ent\"][e]:.3f}, \\n'\n",
    "          # f'Accuracy_Edades(E) = {hist[\"Accuracy_Edades_ent\"][e]:.3f},\\n '\n",
    "          f'Accuracy_Genero(E) = {hist[\"Accuracy_Genero_ent\"][e]:.3f},\\n'\n",
    "          # f'MSE_Edad(E) = {hist[\"MSE_Edad_ent\"][e]:.3f},\\n '\n",
    "          'VALIDACIÓN: \\n'\n",
    "          # f'weighted_F1(V) = {hist[\"weightedF1_val\"][e]:.3f},\\n  '\n",
    "          f'Perdida(V) = {hist[\"perdida_val\"][e]:.3f},\\n  '\n",
    "          # f'Accuracy_Edades(V) = {hist[\"Accuracy_Edades_val\"][e]:.3f}\\n '\n",
    "          f'Accuracy_Genero(V) = {hist[\"Accuracy_Genero_val\"][e]:.3f}\\n '\n",
    "          # f'MSE_Edad(V) = {hist[\"MSE_Edad_val\"][e]:.3f}\\n '\n",
    "          '---------------------------------------------------------------------')\n",
    "\n",
    "  return modelo, mejor_modelo, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def entrena(modelo,\n",
    "            fp_edades,\n",
    "            fp_genero,\n",
    "            fp_reg,\n",
    "            metrica_edades,\n",
    "            metrica_genero,\n",
    "            metrica_edadN,\n",
    "            opt,\n",
    "            entdl,\n",
    "            valdl,\n",
    "            disp,\n",
    "            ckptpath,\n",
    "            n_epocas = 10,\n",
    "            tbdir = 'runs/'):\n",
    "  n_lotes_ent = len(entdl)\n",
    "  n_lotes_val = len(valdl)\n",
    "\n",
    "  hist = {'perdida_ent':np.zeros(n_epocas),\n",
    "          'weightedF1_ent': np.zeros(n_epocas),\n",
    "          'weightedF1_val': np.zeros(n_epocas),\n",
    "          'perdida_val': np.zeros(n_epocas),\n",
    "          'Accuracy_Edades_ent': np.zeros(n_epocas),\n",
    "          'Accuracy_Edades_val': np.zeros(n_epocas),\n",
    "\n",
    "          'Accuracy_Genero_ent': np.zeros(n_epocas),\n",
    "          'Accuracy_Genero_val': np.zeros(n_epocas),\n",
    "\n",
    "          'MSE_Edad_ent': np.zeros(n_epocas),\n",
    "          'MSE_Edad_val': np.zeros(n_epocas)}\n",
    "\n",
    "  # tbwriter = SummaryWriter(tbdir)\n",
    "  perdida_min = th.inf\n",
    "  mejor_modelo = copy.deepcopy(modelo)\n",
    "\n",
    "\n",
    "  for e in range(n_epocas):\n",
    "    # bucle de entrenamiento\n",
    "    modelo.train()\n",
    "    for Xlote, ylote_edades, ylote_genero, ylote_reg, *_ in entdl:\n",
    "      Xlote = Xlote.to(disp)\n",
    "      ylote_edades = ylote_edades.to(disp)\n",
    "      ylote_genero = ylote_genero.to(disp)\n",
    "      ylote_reg = ylote_reg.to(disp)\n",
    "\n",
    "      # perdida_paso, perdida_edad_paso, perdida_genero_paso, perdida_reg_paso, weightedf1\n",
    "      perdida_paso, metrica_edad_paso, metrica_genero_paso, metrica_reg_paso, weightedf1 = paso_ent(modelo,\n",
    "                                            fp_edades,\n",
    "                                            fp_genero,\n",
    "                                            fp_reg,\n",
    "                                            metrica_edades,\n",
    "                                            metrica_genero,\n",
    "                                            metrica_edadN,\n",
    "                                            opt,\n",
    "                                            Xlote,\n",
    "                                            ylote_edades,\n",
    "                                            ylote_genero,\n",
    "                                            ylote_reg)\n",
    "\n",
    "      hist['perdida_ent'][e] += perdida_paso\n",
    "      hist['weightedF1_ent'][e] += weightedf1\n",
    "      hist['Accuracy_Edades_ent'][e] += metrica_edad_paso\n",
    "      hist['Accuracy_Genero_ent'][e] += metrica_genero_paso\n",
    "      hist['MSE_Edad_ent'][e] += metrica_reg_paso\n",
    "\n",
    "    # bucle de validación\n",
    "    modelo.eval()\n",
    "    with th.no_grad():\n",
    "      for Xlote, ylote_edades, ylote_genero, ylote_reg, *_  in valdl:\n",
    "        Xlote = Xlote.to(disp)\n",
    "        ylote_edades = ylote_edades.to(disp)\n",
    "        ylote_genero = ylote_genero.to(disp)\n",
    "        ylote_reg = ylote_reg.to(disp)\n",
    "\n",
    "        y_hat_edades, y_hat_genero, y_hat_reg = modelo(Xlote)\n",
    "\n",
    "        y_hat_genero = y_hat_genero.squeeze().float()\n",
    "        y_hat_reg = y_hat_reg.squeeze().float()\n",
    "\n",
    "        # sacamos las probabilidades\n",
    "        y_prob = F.softmax(y_hat_edades, 1)\n",
    "\n",
    "        # sacamos las clases\n",
    "        y_pred = torch.argmax(y_prob, 1)\n",
    "\n",
    "        weightedf1= f1_score(ylote_edades.cpu(), y_pred.cpu().numpy(), average='weighted')\n",
    "\n",
    "        perdida_genero = F.binary_cross_entropy(y_hat_genero, ylote_genero.float()) #fp_edades\n",
    "        perdida_edad = F.cross_entropy(y_hat_edades, ylote_edades) #fp_genero\n",
    "        perdida_reg = F.mse_loss(y_hat_reg, ylote_reg) #fp_reg\n",
    "\n",
    "        # Puedes ajustar los pesos según sea necesario\n",
    "        w_genero = 1.0\n",
    "        w_edad = 1.0\n",
    "        w_reg = 1.0\n",
    "\n",
    "        # Calcular la pérdida total como la suma ponderada de las pérdidas individuales\n",
    "        perdida_total = w_genero * perdida_genero.float() + w_edad * perdida_edad.float() + w_reg * perdida_reg.float()\n",
    "\n",
    "        metrica_genero_val = metrica_genero(y_hat_genero, ylote_genero.float())\n",
    "        metrica_edad_val = metrica_edades(y_hat_edades, ylote_edades)\n",
    "        metrica_reg_val = metrica_edadN(y_hat_reg, ylote_reg)\n",
    "\n",
    "        hist['perdida_val'][e] += perdida_total\n",
    "        hist['weightedF1_val'][e] += weightedf1\n",
    "        hist['Accuracy_Edades_val'][e] += metrica_edad_val\n",
    "        hist['Accuracy_Genero_val'][e] += metrica_genero_val\n",
    "        hist['MSE_Edad_val'][e] += metrica_reg_val\n",
    "\n",
    "    hist['weightedF1_ent'][e] /=  n_lotes_ent\n",
    "    hist['perdida_ent'][e] /=  n_lotes_ent\n",
    "    hist['perdida_ent'][e] =  hist['perdida_ent'][e]*100\n",
    "    hist['Accuracy_Edades_ent'][e] /= n_lotes_ent\n",
    "    hist['Accuracy_Edades_ent'][e] *= 100\n",
    "\n",
    "    hist['Accuracy_Genero_ent'][e] /= n_lotes_ent\n",
    "    hist['Accuracy_Genero_ent'][e] *= 100\n",
    "\n",
    "    hist['MSE_Edad_ent'][e] /= n_lotes_ent\n",
    "    hist['MSE_Edad_ent'][e] *= 100\n",
    "\n",
    "\n",
    "    hist['weightedF1_val'][e] /=  n_lotes_val\n",
    "    hist['perdida_val'][e] /=  n_lotes_val\n",
    "    hist['perdida_val'][e] =  hist['perdida_val'][e]*100\n",
    "\n",
    "    hist['Accuracy_Edades_val'][e] /= n_lotes_val\n",
    "    hist['Accuracy_Edades_val'][e] *= 100\n",
    "\n",
    "    hist['Accuracy_Genero_val'][e] /= n_lotes_val\n",
    "    hist['Accuracy_Genero_val'][e] *= 100\n",
    "\n",
    "    hist['MSE_Edad_val'][e] /= n_lotes_val\n",
    "    hist['MSE_Edad_val'][e] *= 100\n",
    "    # guardamos checkpoint y copiamos pesos y sesgos del modelo\n",
    "    # actual si disminuye la metrica a monitorear\n",
    "    if hist['perdida_val'][e] < perdida_min:\n",
    "      mejor_modelo.load_state_dict(modelo.state_dict())\n",
    "      guarda_ckpt(ckptpath, modelo, e, opt)\n",
    "\n",
    "    # registra_info_tboard(tbwriter, e, hist)\n",
    "\n",
    "    print(f'\\nÉpoca {e}:\\n '\n",
    "          'ENTRENAMIENTO: \\n'\n",
    "          f'weighted_F1(E) = {hist[\"weightedF1_ent\"][e]:.3f},\\n '\n",
    "          f'Perdida(E) = {hist[\"perdida_ent\"][e]:.3f}, \\n'\n",
    "          f'Accuracy_Edades(E) = {hist[\"Accuracy_Edades_ent\"][e]:.3f},\\n '\n",
    "          f'Accuracy_Genero(E) = {hist[\"Accuracy_Genero_ent\"][e]:.3f},\\n'\n",
    "          f'MSE_Edad(E) = {hist[\"MSE_Edad_ent\"][e]:.3f},\\n '\n",
    "          'VALIDACIÓN: \\n'\n",
    "          f'weighted_F1(V) = {hist[\"weightedF1_val\"][e]:.3f},\\n  '\n",
    "          f'Perdida(V) = {hist[\"perdida_val\"][e]:.3f},\\n  '\n",
    "          f'Accuracy_Edades(V) = {hist[\"Accuracy_Edades_val\"][e]:.3f}\\n '\n",
    "          f'Accuracy_Genero(V) = {hist[\"Accuracy_Genero_val\"][e]:.3f}\\n '\n",
    "          f'MSE_Edad(V) = {hist[\"MSE_Edad_val\"][e]:.3f}\\n '\n",
    "          '---------------------------------------------------------------------')\n",
    "\n",
    "  return modelo, mejor_modelo, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DC = 'cuda:1' if th.cuda.is_available() else 'cpu'\n",
    "LOGDIR = './logs/'\n",
    "N_EPOCAS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrotEnd(nn.Module):\n",
    "    def __init__(self,dim_inicial, clases_age=NUM_CLASES_AGE, dropout=0.0, extract=False, onlyGender=False):\n",
    "        super(FrotEnd, self).__init__()\n",
    "        self.onlyGender= onlyGender\n",
    "\n",
    "        self.age_classification = nn.Sequential(\n",
    "            nn.Linear(dim_inicial,dim_inicial),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(dim_inicial),\n",
    "            nn.Linear(dim_inicial,clases_age),\n",
    "            # nn.Softmax()\n",
    "        )\n",
    "\n",
    "        self.gender = nn.Sequential(\n",
    "            nn.Linear(dim_inicial,dim_inicial),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(dim_inicial),\n",
    "            nn.Linear(dim_inicial,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.age_regression = nn.Sequential(\n",
    "            nn.Linear(dim_inicial,dim_inicial),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(dim_inicial),\n",
    "            nn.Linear(dim_inicial,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.onlyGender == False:\n",
    "            age_classes = self.age_classification(x)\n",
    "            age_classes = age_classes\n",
    "        # age_classes = age_classes.float()\n",
    "        \n",
    "        gender = self.gender(x)\n",
    "        gender = gender.squeeze().float()\n",
    "        \n",
    "        if self.onlyGender == False:\n",
    "            age_regression = self.age_regression(x)\n",
    "            age_regression = age_regression.squeeze().float()\n",
    "        if self.onlyGender == False:\n",
    "            return age_classes , gender , age_regression\n",
    "        else:\n",
    "            return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pooling import StatsPooling, AttnPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# blocks\n",
    "def dense_norm_relu(in_size, out_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_size, out_size),\n",
    "        nn.BatchNorm1d(out_size),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "def conv_bn_act(in_size, out_size, kernel_size, stride=1, dilation=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv1d(in_size, out_size, kernel_size, stride, dilation=dilation),\n",
    "        nn.BatchNorm1d(out_size),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "\n",
    "def sepconv_bn(in_size, out_size, kernel_size, stride=1, dilation=1, padding=None):\n",
    "    if padding is None:\n",
    "        padding = (kernel_size-1)//2\n",
    "    return nn.Sequential(\n",
    "        torch.nn.Conv1d(in_size, in_size, kernel_size, \n",
    "                        stride=stride, dilation=dilation, groups=in_size,\n",
    "                        padding=padding),\n",
    "        torch.nn.Conv1d(in_size, out_size, kernel_size=1),\n",
    "        nn.BatchNorm1d(out_size)\n",
    "    )\n",
    "\n",
    "\n",
    "# Main block B_i\n",
    "class QnetBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, kernel_size, stride=1,\n",
    "                R=5):\n",
    "        super().__init__()\n",
    "       \n",
    "\n",
    "        self.layers = nn.ModuleList(sepconv_bn(in_size, out_size, kernel_size, stride))\n",
    "        for i in range(R - 1):\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(sepconv_bn(out_size, out_size, kernel_size, stride))\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "\n",
    "        self.residual = nn.ModuleList()\n",
    "        self.residual.append(torch.nn.Conv1d(in_size, out_size, kernel_size=1))\n",
    "        self.residual.append(torch.nn.BatchNorm1d(out_size))\n",
    "        self.residual = nn.Sequential(*self.residual)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.residual(x) + self.layers(x))\n",
    "\n",
    "class QuartzNet(nn.Module):\n",
    "    def __init__(self, n_mels, num_classes=NUM_CLASSES, onlyGender=False):\n",
    "        super().__init__()\n",
    "        self.onlyGender= onlyGender\n",
    "\n",
    "        self.c1 = sepconv_bn(n_mels, 512, kernel_size=3, stride=1)\n",
    "        self.blocks = nn.Sequential(\n",
    "                #         in   out  k   s  R\n",
    "                QnetBlock(512, 512, 5, 1, R=2),\n",
    "                QnetBlock(512, 512, 7, 1, R=2),\n",
    "                QnetBlock(512, 512, 9, 1, R=2),\n",
    "        )\n",
    "\n",
    "        self.pooling = StatsPooling()\n",
    "        self.lin = nn.Linear(2 * 512, 512)\n",
    "\n",
    "        self.c3 = dense_norm_relu(512, 512)\n",
    "        self.c4 = dense_norm_relu(512, 512)\n",
    "\n",
    "        self.frontEnd = FrotEnd(512, onlyGender=self.onlyGender)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        # x= x.permute(1,0,2)\n",
    "        # print(x.shape)\n",
    "        c1 = self.c1(x)\n",
    "        # print(c1.shape)\n",
    "        x = self.blocks(c1)\n",
    "        # print(x.shape)\n",
    "        x = self.pooling(x)\n",
    "        # print(x.shape)\n",
    "        x= self.lin(x)\n",
    "\n",
    "        x = self.c3(x)\n",
    "        x=self.c4(x)\n",
    "        \n",
    "        if self.onlyGender==False:\n",
    "            class_edad, genero, edad_num = self.frontEnd(x)\n",
    "\n",
    "            return class_edad.float(), genero.float(), edad_num.float()\n",
    "        else:\n",
    "            genero = self.frontEnd(x)\n",
    "\n",
    "            return genero.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wave =tensor([[-740.4886, -725.9606, -751.2870,  ..., -319.0290, -307.1799,\n",
      "         -272.4417],\n",
      "        [  -4.0167,    5.3544,  -10.8716,  ...,   60.5764,   65.0651,\n",
      "           50.1706],\n",
      "        [   7.7824,   -2.4532,   -2.2802,  ...,  -87.2081,  -85.6640,\n",
      "          -72.0445],\n",
      "        ...,\n",
      "        [  -1.4578,   -9.1463,  -10.3715,  ...,   -6.3823,   -4.1764,\n",
      "           -6.5597],\n",
      "        [  -1.6452,   -2.6420,   -4.4581,  ...,  -24.0902,  -19.0038,\n",
      "           -7.6171],\n",
      "        [   2.4216,   -6.2927,   -6.0136,  ...,    9.1047,    5.7166,\n",
      "          -17.1064]]), Categoría = 0\n"
     ]
    }
   ],
   "source": [
    "it_ent = iter(ds_ent)\n",
    "# waveform, edad, genero, edad_num, sr = next(it_ent)\n",
    "waveform, genero= next(it_ent)\n",
    "# waveform, edad , genero, edad_num= next(it_ent)\n",
    "\n",
    "print(f'wave ={waveform}, Categoría = {genero}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 81])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #\n",
       "========================================================================================================================\n",
       "QuartzNet                                     [1, 23, 81]               [1, 8]                    --\n",
       "├─Sequential: 1-1                             [1, 23, 81]               [1, 512, 81]              --\n",
       "│    └─Conv1d: 2-1                            [1, 23, 81]               [1, 23, 81]               92\n",
       "│    └─Conv1d: 2-2                            [1, 23, 81]               [1, 512, 81]              12,288\n",
       "│    └─BatchNorm1d: 2-3                       [1, 512, 81]              [1, 512, 81]              1,024\n",
       "├─Sequential: 1-2                             [1, 512, 81]              [1, 512, 81]              --\n",
       "│    └─QnetBlock: 2-4                         [1, 512, 81]              [1, 512, 81]              --\n",
       "│    │    └─Sequential: 3-1                   [1, 512, 81]              [1, 512, 81]              263,680\n",
       "│    │    └─Sequential: 3-2                   [1, 512, 81]              [1, 512, 81]              533,504\n",
       "│    └─QnetBlock: 2-5                         [1, 512, 81]              [1, 512, 81]              --\n",
       "│    │    └─Sequential: 3-3                   [1, 512, 81]              [1, 512, 81]              263,680\n",
       "│    │    └─Sequential: 3-4                   [1, 512, 81]              [1, 512, 81]              535,552\n",
       "│    └─QnetBlock: 2-6                         [1, 512, 81]              [1, 512, 81]              --\n",
       "│    │    └─Sequential: 3-5                   [1, 512, 81]              [1, 512, 81]              263,680\n",
       "│    │    └─Sequential: 3-6                   [1, 512, 81]              [1, 512, 81]              537,600\n",
       "├─StatsPooling: 1-3                           [1, 512, 81]              [1, 1024]                 --\n",
       "├─Linear: 1-4                                 [1, 1024]                 [1, 512]                  524,800\n",
       "├─Sequential: 1-5                             [1, 512]                  [1, 512]                  --\n",
       "│    └─Linear: 2-7                            [1, 512]                  [1, 512]                  262,656\n",
       "│    └─BatchNorm1d: 2-8                       [1, 512]                  [1, 512]                  1,024\n",
       "│    └─ReLU: 2-9                              [1, 512]                  [1, 512]                  --\n",
       "├─Sequential: 1-6                             [1, 512]                  [1, 512]                  --\n",
       "│    └─Linear: 2-10                           [1, 512]                  [1, 512]                  262,656\n",
       "│    └─BatchNorm1d: 2-11                      [1, 512]                  [1, 512]                  1,024\n",
       "│    └─ReLU: 2-12                             [1, 512]                  [1, 512]                  --\n",
       "├─FrotEnd: 1-7                                [1, 512]                  [1, 8]                    --\n",
       "│    └─Sequential: 2-13                       [1, 512]                  [1, 8]                    --\n",
       "│    │    └─Linear: 3-7                       [1, 512]                  [1, 512]                  262,656\n",
       "│    │    └─ReLU: 3-8                         [1, 512]                  [1, 512]                  --\n",
       "│    │    └─BatchNorm1d: 3-9                  [1, 512]                  [1, 512]                  1,024\n",
       "│    │    └─Linear: 3-10                      [1, 512]                  [1, 8]                    4,104\n",
       "│    └─Sequential: 2-14                       [1, 512]                  [1, 1]                    --\n",
       "│    │    └─Linear: 3-11                      [1, 512]                  [1, 512]                  262,656\n",
       "│    │    └─ReLU: 3-12                        [1, 512]                  [1, 512]                  --\n",
       "│    │    └─BatchNorm1d: 3-13                 [1, 512]                  [1, 512]                  1,024\n",
       "│    │    └─Linear: 3-14                      [1, 512]                  [1, 1]                    513\n",
       "│    │    └─Sigmoid: 3-15                     [1, 1]                    [1, 1]                    --\n",
       "│    └─Sequential: 2-15                       [1, 512]                  [1, 1]                    --\n",
       "│    │    └─Linear: 3-16                      [1, 512]                  [1, 512]                  262,656\n",
       "│    │    └─ReLU: 3-17                        [1, 512]                  [1, 512]                  --\n",
       "│    │    └─BatchNorm1d: 3-18                 [1, 512]                  [1, 512]                  1,024\n",
       "│    │    └─Linear: 3-19                      [1, 512]                  [1, 1]                    513\n",
       "========================================================================================================================\n",
       "Total params: 4,259,430\n",
       "Trainable params: 4,259,430\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 196.33\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 8.69\n",
       "Params size (MB): 17.04\n",
       "Estimated Total Size (MB): 25.73\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_layer = QuartzNet(23)\n",
    "summary(test_layer, (1, 23,81), device='cpu',col_names=['input_size', 'output_size', 'num_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 23, 81])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch = next(iter(dl_ent))\n",
    "train_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Red_xvect = QuartzNet(23)\n",
    "edad, gen, edNum = Red_xvect(train_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: wandb 0.16.0\n",
      "Uninstalling wandb-0.16.0:\n",
      "  Would remove:\n",
      "    /home/ar/miniconda3/envs/Aixa/bin/wandb\n",
      "    /home/ar/miniconda3/envs/Aixa/bin/wb\n",
      "    /home/ar/miniconda3/envs/Aixa/lib/python3.8/site-packages/wandb-0.16.0.dist-info/*\n",
      "    /home/ar/miniconda3/envs/Aixa/lib/python3.8/site-packages/wandb/*\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'wandb' has no attribute 'log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb Cell 48\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m opt \u001b[39m=\u001b[39m Adam(red\u001b[39m.\u001b[39mparameters(),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m            lr\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# # start a new wandb run to track this script\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# wandb.init(\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#     # set the wandb project where this run will be logged\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#     }\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m red_QuartzNet_TIMIT, mejor_QuartzNet_TIMIT, hist_QuartzNet_TIMIT \u001b[39m=\u001b[39m entrena_Timit(red,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m                                    perdida_edades,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m                                    perdida_genero,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m                                    perdida_edadN,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m                                    exactitud,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m                                    exactitud,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m                                    metrica_edadN,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m                                    opt,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m                                    dl_ent,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m                                    dl_val,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m                                    DC,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m                                    LOGDIR \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m/red_Quartznet_Gender_TIMIT.pt\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m                                    n_epocas\u001b[39m=\u001b[39;49mN_EPOCAS,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m                                    tbdir \u001b[39m=\u001b[39;49m LOGDIR)\n",
      "\u001b[1;32m/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb Cell 48\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=138'>139</a>\u001b[0m   guarda_ckpt(ckptpath, modelo, e, opt)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=140'>141</a>\u001b[0m \u001b[39m# registra_info_tboard(tbwriter, e, hist)\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=143'>144</a>\u001b[0m wandb\u001b[39m.\u001b[39;49mlog({\u001b[39m\"\u001b[39m\u001b[39mValidation_acc_genero\u001b[39m\u001b[39m\"\u001b[39m: hist[\u001b[39m\"\u001b[39m\u001b[39mAccuracy_Genero_val\u001b[39m\u001b[39m\"\u001b[39m][e],\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=144'>145</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mValidation_loss_total\u001b[39m\u001b[39m\"\u001b[39m: hist[\u001b[39m\"\u001b[39m\u001b[39mperdida_val\u001b[39m\u001b[39m\"\u001b[39m][e] })\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=146'>147</a>\u001b[0m wandb\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mTrain_acc_genero\u001b[39m\u001b[39m\"\u001b[39m: hist[\u001b[39m\"\u001b[39m\u001b[39mAccuracy_Genero_ent\u001b[39m\u001b[39m\"\u001b[39m][e], \n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=147'>148</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTrain_loss_total\u001b[39m\u001b[39m\"\u001b[39m: hist[\u001b[39m\"\u001b[39m\u001b[39mperdida_ent\u001b[39m\u001b[39m\"\u001b[39m][e] })\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=149'>150</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mÉpoca \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=150'>151</a>\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mENTRENAMIENTO: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=151'>152</a>\u001b[0m       \u001b[39m# f'weighted_F1(E) = {hist[\"weightedF1_ent\"][e]:.3f},\\n '\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=161'>162</a>\u001b[0m       \u001b[39m# f'MSE_Edad(V) = {hist[\"MSE_Edad_val\"][e]:.3f}\\n '\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B192.168.20.146/home/ar/Data/AixaPL/Version1/PCIC23/x-vector/Quartznet.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=162'>163</a>\u001b[0m       \u001b[39m'\u001b[39m\u001b[39m---------------------------------------------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'wandb' has no attribute 'log'"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "red= QuartzNet(23, onlyGender=True)\n",
    "red.to(DC)\n",
    "perdida_edades = nn.CrossEntropyLoss(weight=None,\n",
    "                              reduction='mean',\n",
    "                              label_smoothing=0.01)\n",
    "perdida_genero = nn.BCELoss(weight=None, reduction='mean')\n",
    "perdida_edadN = nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "metrica_edadN = nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "opt = Adam(red.parameters(),\n",
    "           lr=0.0001)\n",
    "\n",
    "\n",
    "# # start a new wandb run to track this script\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"Quartznet\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.0001,\n",
    "#     \"architecture\": \"Quartznet\",\n",
    "#     \"dataset\": \"CCv2\",\n",
    "#     \"epochs\": 100,\n",
    "#     \"onlyGender\": 1\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "red_QuartzNet_TIMIT, mejor_QuartzNet_TIMIT, hist_QuartzNet_TIMIT = entrena_Timit(red,\n",
    "                                   perdida_edades,\n",
    "                                   perdida_genero,\n",
    "                                   perdida_edadN,\n",
    "                                   exactitud,\n",
    "                                   exactitud,\n",
    "                                   metrica_edadN,\n",
    "                                   opt,\n",
    "                                   dl_ent,\n",
    "                                   dl_val,\n",
    "                                   DC,\n",
    "                                   LOGDIR + '/red_Quartznet_Gender_TIMIT.pt',\n",
    "                                   n_epocas=N_EPOCAS,\n",
    "                                   tbdir = LOGDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supongamos que tienes un diccionario llamado hist que contiene tus métricas\n",
    "# hist = ...\n",
    "\n",
    "# Extrae los valores de Accuracy_Genero_ent y Accuracy_Genero_val\n",
    "accuracy_genero_ent = hist_QuartzNet_TIMIT['Accuracy_Genero_ent']\n",
    "accuracy_genero_val = hist_QuartzNet_TIMIT['Accuracy_Genero_val']\n",
    "\n",
    "# Crea un gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(accuracy_genero_ent) + 1), accuracy_genero_ent, label='Accuracy_Genero_ent')\n",
    "plt.plot(range(1, len(accuracy_genero_val) + 1), accuracy_genero_val, label='Accuracy_Genero_val')\n",
    "\n",
    "# Agrega etiquetas y título\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparación de Accuracy_Genero_ent y Accuracy_Genero_val')\n",
    "plt.legend()\n",
    "\n",
    "# Guarda el gráfico en un archivo (puedes cambiar el formato según tus necesidades)\n",
    "plt.savefig('./images/comparacion_accuracy_genero_Xvector_TIMIT_00001.png')\n",
    "\n",
    "\n",
    "\n",
    "perdida_ent = hist_QuartzNet_TIMIT['perdida_ent']\n",
    "perdida_val = hist_QuartzNet_TIMIT['perdida_val']\n",
    "\n",
    "# Crea un gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(perdida_ent) + 1), perdida_ent, label='perdida_ent')\n",
    "plt.plot(range(1, len(perdida_val) + 1), perdida_val, label='perdida_val')\n",
    "\n",
    "# Agrega etiquetas y título\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparación de perdida_ent y perdida_val')\n",
    "plt.legend()\n",
    "\n",
    "# Guarda el gráfico en un archivo (puedes cambiar el formato según tus necesidades)\n",
    "plt.savefig('./images/comparacion_perdida_Xvector_TIMIT_00001.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "aixa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
